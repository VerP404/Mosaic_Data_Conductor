import os
import time
import json
import fnmatch

from dagster import sensor, RunRequest, SkipReason

from etl_wo.config.config import ORGANIZATIONS
from etl_wo.jobs.kvazar import (
    kvazar_job_eln,
    kvazar_job_emd,
    kvazar_job_recipes,
    kvazar_job_death,
    kvazar_job_reference,
)

MIN_FILE_AGE_SECONDS = 60


def _load_state(context) -> dict:
    """–ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ cursor —Å–ª–æ–≤–∞—Ä—å –≤–∏–¥–∞ {filename: run_key}."""
    if context.cursor:
        return json.loads(context.cursor)
    return {}


def _save_state(context, state: dict):
    """–°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ª–æ–≤–∞—Ä—å {filename: run_key} –≤ cursor —Å–µ–Ω—Å–æ—Ä–∞."""
    context.update_cursor(json.dumps(state, ensure_ascii=False))


def create_sensor(job, sensor_name, data_folder, table_name, mapping_file):
    @sensor(job=job, name=sensor_name)
    def _sensor(context):
        sensor_state = _load_state(context)  # {filename: run_key}

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ mapping.json
        if not os.path.exists(mapping_file):
            context.log.info(f"‚ùå –§–∞–π–ª –º–∞–ø–ø–∏–Ω–≥–∞ {mapping_file} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
            yield SkipReason("Mapping file not found.")
            return

        with open(mapping_file, "r", encoding="utf-8") as f:
            mapping = json.load(f)
        table_config = mapping.get("tables", {}).get(table_name)
        if not table_config:
            context.log.info(f"‚ùå –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã '{table_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ {mapping_file}.")
            yield SkipReason("Mapping config for table not found.")
            return

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø–∞–ø–∫–∏ —Å –¥–∞–Ω–Ω—ã–º–∏
        if not os.path.exists(data_folder):
            context.log.info(f"‚ùå –ü–∞–ø–∫–∞ {data_folder} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
            yield SkipReason("Data folder not found.")
            return

        files = os.listdir(data_folder)
        if not files:
            context.log.info(f"üìÇ –ü–∞–ø–∫–∞ {data_folder} –ø—É—Å—Ç–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–∏–∫.")
            yield SkipReason("–ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –≤ –ø–∞–ø–∫–µ.")
            return

        now = time.time()
        valid_files = []
        invalid_files = []

        # –ü–æ–ª—É—á–∞–µ–º —à–∞–±–ª–æ–Ω —Ñ–∞–π–ª–æ–≤
        file_pattern = table_config.get("file", {}).get("file_pattern", "")
        file_format = table_config.get("file", {}).get("file_format", "")
        valid_pattern = f"{file_pattern}.{file_format}"

        for file in files:
            file_path = os.path.join(data_folder, file)
            if fnmatch.fnmatch(file, valid_pattern):
                mod_time = os.path.getmtime(file_path)
                age = now - mod_time
                if age >= MIN_FILE_AGE_SECONDS:
                    valid_files.append(file)
                else:
                    context.log.info(f"–§–∞–π–ª {file} –µ—â—ë –Ω–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–≥—Ä—É–∂–µ–Ω (–≤–æ–∑—Ä–∞—Å—Ç {age:.0f} —Å–µ–∫.).")
            else:
                invalid_files.append(file)

        for file in invalid_files:
            file_path = os.path.join(data_folder, file)
            try:
                os.remove(file_path)
                context.log.info(f"–£–¥–∞–ª—ë–Ω –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π —Ñ–∞–π–ª: {file_path}")
            except Exception as e:
                context.log.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Ñ–∞–π–ª {file_path}: {e}")

        if not valid_files:
            context.log.info("–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è.")
            yield SkipReason("–ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤.")
            return

        for file in valid_files:
            existing_run_key = sensor_state.get(file)

            if existing_run_key:
                runs = context.instance.get_runs()
                matching_run = next(
                    (r for r in runs if r.tags.get("dagster/run_key") == existing_run_key), None
                )

                if matching_run:
                    if not matching_run.is_finished:
                        context.log.info(f"–§–∞–π–ª {file} —É–∂–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.")
                        continue
                    elif matching_run.is_success:
                        try:
                            os.remove(os.path.join(data_folder, file))
                            context.log.info(f"–§–∞–π–ª {file} —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –∏ —É–¥–∞–ª—ë–Ω.")
                        except Exception as e:
                            context.log.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file}: {e}")
                        del sensor_state[file]
                        continue
                    elif matching_run.is_failure:
                        context.log.warning(f"–§–∞–π–ª {file} –∑–∞–≤–µ—Ä—à–∏–ª—Å—è –æ—à–∏–±–∫–æ–π. –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º.")
                        del sensor_state[file]

            if file not in sensor_state:
                new_run_key = f"{file}-{int(time.time())}"
                context.log.info(f"–ó–∞–ø—É—Å–∫ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–ª—è —Ñ–∞–π–ª–∞ {file} c run_key={new_run_key}.")

                # ‚úÖ –î–æ–±–∞–≤–ª—è–µ–º –í–°–ï –±–ª–æ–∫–∏ –≤ –∫–æ–Ω—Ñ–∏–≥:
                run_config = {
                    "ops": {
                        "kvazar_db_check": {
                            "config": {
                                "organization": ORGANIZATIONS,  # –º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫
                                "tables": [table_name]
                            }
                        },
                        "kvazar_extract": {
                            "config": {
                                "data_folder": data_folder,
                                "mapping_file": mapping_file,
                                "table_name": table_name,
                            }
                        },
                        "kvazar_transform": {
                            "config": {
                                "mapping_file": mapping_file,
                                "table_name": table_name
                            }
                        },
                        "kvazar_load": {
                            "config": {
                                "table_name": table_name,
                                "data_folder": data_folder,
                                "mapping_file": mapping_file
                            }
                        }
                    }
                }

                yield RunRequest(run_key=new_run_key, run_config=run_config)
                sensor_state[file] = new_run_key

        _save_state(context, sensor_state)

    return _sensor


# ‚úÖ –°–æ–∑–¥–∞–Ω–∏–µ —Å–µ–Ω—Å–æ—Ä–æ–≤
kvazar_sensor_eln = create_sensor(
    kvazar_job_eln,
    "kvazar_sensor_eln",
    "etl_wo/data/kvazar/eln",
    "load_data_sick_leave_sheets",
    "etl_wo/config/mapping.json"
)

kvazar_sensor_emd = create_sensor(
    kvazar_job_emd,
    "kvazar_sensor_emd",
    "etl_wo/data/kvazar/emd",
    "load_data_emd",
    "etl_wo/config/mapping.json"
)

kvazar_sensor_recipes = create_sensor(
    kvazar_job_recipes,
    "kvazar_sensor_recipes",
    "etl_wo/data/kvazar/recipe",
    "load_data_recipes",
    "etl_wo/config/mapping.json"
)

kvazar_sensor_death = create_sensor(
    kvazar_job_death,
    "kvazar_sensor_death",
    "etl_wo/data/kvazar/death",
    "load_data_death",
    "etl_wo/config/mapping.json"
)

kvazar_sensor_reference = create_sensor(
    kvazar_job_reference,
    "kvazar_sensor_reference",
    "etl_wo/data/kvazar/reference",
    "load_data_reference",
    "etl_wo/config/mapping.json"
)
