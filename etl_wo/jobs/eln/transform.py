import os
import json
import pandas as pd
from dagster import asset, Field, String, OpExecutionContext, AssetIn
from etl_wo.common.connect_db import connect_to_db
from etl_wo.config.config import ORGANIZATIONS
from etl_wo.jobs.eln.flow_config import MAPPING_FILE, TABLE_NAME


@asset(
    config_schema={
        "mapping_file": Field(String, default_value=MAPPING_FILE),
        "table_name": Field(String, default_value=TABLE_NAME),
        "db_alias": Field(String, default_value="default"),
    },
    ins={"eln_extract": AssetIn()}  # –º–µ–Ω—è–µ–º –∫–ª—é—á —Å "sick_leave_extract" –Ω–∞ "eln_extract"
)
def eln_transform(context: OpExecutionContext, eln_extract: dict) -> dict:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è sick_leave:
      1. –ó–∞–≥—Ä—É–∂–∞–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–∞–ø–ø–∏–Ω–≥–∞ –∏–∑ mapping.json –∏ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ—Ç —Å—Ç–æ–ª–±—Ü—ã.
      2. –ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã (varchar) –∏–∑ —Å—Ö–µ–º—ã —Ç–∞–±–ª–∏—Ü—ã –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.
      3. –î–æ–±–∞–≤–ª—è–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã —Å–æ –∑–Ω–∞—á–µ–Ω–∏–µ–º "-" –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.
      4. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π —Å–ª–æ–≤–∞—Ä—å —Å –∫–ª—é—á–∞–º–∏ "table_name" –∏ "data".
    """
    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    config = context.op_config
    mapping_file = config["mapping_file"]
    table_name = config["table_name"]
    db_alias = config["db_alias"]

    # –ò–∑–≤–ª–µ–∫–∞–µ–º DataFrame –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —ç—Ç–∞–ø–∞
    df = eln_extract.get("data")
    if df is None:
        context.log.error("‚ùå –û—à–∏–±–∫–∞: –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏!")
        raise ValueError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏.")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–∞–ø–ø–∏–Ω–≥ –∏ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã —Å–æ–≥–ª–∞—Å–Ω–æ mapping.json
    with open(mapping_file, "r", encoding="utf-8") as f:
        mappings = json.load(f)
    table_config = mappings.get("tables", {}).get(table_name, {})
    column_mapping = table_config.get("mapping_fields", {})

    # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã
    df = df.rename(columns=column_mapping)
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º DataFrame —Ç–æ–ª—å–∫–æ –∫–æ–ª–æ–Ω–∫–∞–º–∏ –∏–∑ –º–∞–ø–ø–∏–Ω–≥–∞
    df = df[list(column_mapping.values())]

    # –ü–æ–ª—É—á–∞–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã (varchar) –∏–∑ —Å—Ö–µ–º—ã —Ç–∞–±–ª–∏—Ü—ã –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö
    engine, conn = connect_to_db(db_alias=db_alias, organization=ORGANIZATIONS, context=context)
    sql = f"""
      SELECT column_name 
      FROM information_schema.columns 
      WHERE table_name = '{table_name}' 
        AND data_type = 'character varying';
    """
    with conn.cursor() as cursor:
        cursor.execute(sql)
        db_columns = [row[0] for row in cursor.fetchall()]
    conn.close()

    if not db_columns:
        context.log.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã {table_name}.")
        raise ValueError(f"–ù–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã {table_name}.")

    context.log.info(f"‚úÖ –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –∏–∑ –ë–î (varchar): {db_columns}")

    # –ó–∞–ø–æ–ª–Ω—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º "-"
    for col in db_columns:
        if col not in df.columns:
            df[col] = "-"

    context.log.info(f"üîÑ –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è {table_name} –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {len(df)}")
    return {"table_name": table_name, "data": df}
