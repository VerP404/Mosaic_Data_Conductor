import json
import pandas as pd
from dagster import asset, Field, String, OpExecutionContext, AssetIn

from etl_wo.common.connect_db import connect_to_db
from etl_wo.config.config import ORGANIZATIONS
from etl_wo.jobs.job1.flow_config import MAPPING_FILE, TABLE_NAME, NORMAL_TABLE, COMPLEX_TABLE

@asset(
    config_schema={
        "mapping_file": Field(String, default_value=MAPPING_FILE),
        "table_name": Field(String, default_value=TABLE_NAME),
        "normal_table": Field(String, default_value=NORMAL_TABLE),
        "complex_table": Field(String, default_value=COMPLEX_TABLE),
        # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è –≤—ã–±–æ—Ä–∞ –±–∞–∑—ã, –µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è:
        "db_alias": Field(String, default_value="default"),
    },
    ins={"talon_extract2": AssetIn()}
)
def talon_transform2(context: OpExecutionContext, talon_extract2: dict) -> dict:
    """
    –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö:
      1. –ó–∞–≥—Ä—É–∂–∞–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–∞–ø–ø–∏–Ω–≥–∞ –∏–∑ mapping.json –∏ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ—Ç —Å—Ç–æ–ª–±—Ü—ã.
      2. –ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –∏–∑ —Å—Ö–µ–º—ã —Ç–∞–±–ª–∏—Ü—ã –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö.
      3. –ï—Å–ª–∏ –≤ DataFrame –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã, –¥–æ–±–∞–≤–ª—è–µ—Ç –∏—Ö —Å–æ –∑–Ω–∞—á–µ–Ω–∏–µ–º –¥–µ—Ñ–æ–ª—Ç–∞ "-".
      4. –î–æ–±–∞–≤–ª—è–µ—Ç —Å—Ç–æ–ª–±–µ—Ü "is_complex" (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é False) –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ –∑–∞–ø–∏—Å–∏
         (–µ—Å–ª–∏ –ø–æ –ø–∞—Ä–µ (talon, source) –Ω–∞–π–¥–µ–Ω–æ –±–æ–ª–µ–µ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏).
      5. –î–µ–ª–∏—Ç –¥–∞–Ω–Ω—ã–µ –Ω–∞ –¥–≤–∞ DataFrame: normal –∏ complex.
      6. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å –∫–ª—é—á–∞–º–∏ "normal" –∏ "complex", –≥–¥–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —É–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –∏–º—è —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏.
    """
    # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    config = context.op_config
    mapping_file = config["mapping_file"]
    table_name = config["table_name"]
    normal_table = config["normal_table"]
    complex_table = config["complex_table"]
    db_alias = config["db_alias"]

    # –ò–∑–≤–ª–µ–∫–∞–µ–º DataFrame –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —ç—Ç–∞–ø–∞
    df = talon_extract2.get("data")
    if df is None:
        context.log.error("‚ùå –û—à–∏–±–∫–∞: –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏!")
        raise ValueError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏.")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–∞–ø–ø–∏–Ω–≥ –∏ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã
    with open(mapping_file, "r", encoding="utf-8") as f:
        mappings = json.load(f)
    table_config = mappings.get("tables", {}).get(table_name, {})
    column_mapping = table_config.get("mapping_fields", {})

    # –ü—Ä–∏–≤–æ–¥–∏–º —Å—Ç–æ–ª–±—Ü—ã –∫ —Ç—Ä–µ–±—É–µ–º–æ–º—É –≤–∏–¥—É
    df = df.rename(columns=column_mapping)
    df = df[list(column_mapping.values())]

    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ (—Ç–æ–ª—å–∫–æ –¥–ª—è varchar) –∏–∑ —Å—Ö–µ–º—ã —Ç–∞–±–ª–∏—Ü—ã –ë–î
    engine, conn = connect_to_db(db_alias=db_alias, organization=ORGANIZATIONS, context=context)
    sql = f"""
      SELECT column_name 
      FROM information_schema.columns 
      WHERE table_name = '{table_name}' 
        AND data_type = 'character varying';
    """
    with conn.cursor() as cursor:
        cursor.execute(sql)
        db_columns = [row[0] for row in cursor.fetchall()]
    conn.close()

    if not db_columns:
        context.log.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã {table_name} –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö.")
        raise ValueError(f"–ù–µ—Ç —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã {table_name}.")

    context.log.info(f"‚úÖ –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –∏–∑ –ë–î (varchar): {db_columns}")

    # –ó–∞–ø–æ–ª–Ω—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º
    for col in db_columns:
        if col not in df.columns:
            df[col] = "-"

    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–æ–ª–±–µ—Ü is_complex –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    df["is_complex"] = False

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ –∑–∞–ø–∏—Å–∏: –µ—Å–ª–∏ –ø–æ –ø–∞—Ä–µ (talon, source) –Ω–∞–π–¥–µ–Ω–æ –±–æ–ª–µ–µ –æ–¥–Ω–æ–π –∑–∞–ø–∏—Å–∏,
    # –ø–æ–º–µ—á–∞–µ–º –∏—Ö –∫–∞–∫ –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ
    grouped = df.groupby(["talon", "source"])
    for (talon, source), group in grouped:
        if len(group) > 1:
            df.loc[group.index, "is_complex"] = True

    # –î–µ–ª–∏–º DataFrame –Ω–∞ –¥–≤–∞: –æ–±—ã—á–Ω—ã–µ –∏ –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ –∑–∞–ø–∏—Å–∏
    normal_df = df[df["is_complex"] == False].copy()
    complex_df = df[df["is_complex"] == True].copy()

    normal_count = len(normal_df)
    complex_count = len(complex_df)
    context.log.info(
        f"üîÑ –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {len(df)}. "
        f"–û–±—ã—á–Ω—ã—Ö: {normal_count}. –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã—Ö: {complex_count}."
    )

    return {
        "normal": {"table_name": normal_table, "data": normal_df},
        "complex": {"table_name": complex_table, "data": complex_df}
    }
