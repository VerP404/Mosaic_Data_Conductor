import json
import pandas as pd
from dagster import asset, OpExecutionContext

@asset
def talon_transform(context: OpExecutionContext, talon_extract: dict):
    """
    –ü—Ä–∏–º–µ–Ω—è–µ—Ç –º–∞–ø–ø–∏–Ω–≥ –∫–æ–ª–æ–Ω–æ–∫, –∑–∞–ø–æ–ª–Ω—è–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–µ—Ñ–æ–ª—Ç–∞–º–∏,
    –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –∫–∞–∫–∏–µ —Å—Ç—Ä–æ–∫–∏ —è–≤–ª—è—é—Ç—Å—è –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–º–∏ (–µ—Å–ª–∏ –¥–ª—è –ø–∞—Ä—ã (talon, source)
    –Ω–∞–π–¥–µ–Ω–æ –±–æ–ª–µ–µ –æ–¥–Ω–æ–π –∑–∞–ø–∏—Å–∏). –ó–∞—Ç–µ–º —Ä–∞–∑–¥–µ–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –Ω–∞ –¥–≤–∞ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞.
    """
    if talon_extract is None:
        text_value = f"‚ùå –û—à–∏–±–∫–∞: extract –Ω–µ –ø–µ—Ä–µ–¥–∞–ª –¥–∞–Ω–Ω—ã–µ!"
        context.log.info(text_value)
        raise ValueError(text_value)

    table_name = talon_extract.get("table_name", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞")
    df = talon_extract.get("data", None)
    if df is None:
        text_value = f"‚ùå –û—à–∏–±–∫–∞: –î–∞–Ω–Ω—ã–µ –¥–ª—è {table_name} –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç!"
        context.log.info(text_value)
        raise ValueError(text_value)

    MAPPING_PATH = "etl_wo/config/mapping.json"
    with open(MAPPING_PATH, "r", encoding="utf-8") as f:
        mappings = json.load(f)
    table_config = mappings["tables"].get(table_name, {})
    column_mapping = table_config.get("mapping_fields", {})

    df = df.rename(columns=column_mapping)
    df = df[list(column_mapping.values())]

    required_columns = [
        "talon", "report_period", "source", "account_number", "upload_date", "status",
        "talon_type", "goal", "patient", "birth_date", "gender", "policy", "smo_code", "enp",
        "treatment_start", "treatment_end", "doctor", "doctor_profile", "staff_position",
        "department", "care_conditions", "medical_assistance_type", "disease_type", "main_disease_character",
        "visits", "mo_visits", "home_visits", "case_code", "main_diagnosis", "additional_diagnosis",
        "mp_profile", "bed_profile", "dispensary_monitoring", "specialty", "outcome", "result",
        "operator", "initial_input_date", "last_change_date", "amount", "sanctions", "ksg", "uet",
        "additional_status_info", "is_complex"
    ]

    for col in required_columns:
        if col not in df.columns and col != "is_complex":
            df[col] = "-"

    df["is_complex"] = False

    grouped = df.groupby(["talon", "source"])
    for (talon, source), group in grouped:
        if len(group) > 1:
            df.loc[group.index, "is_complex"] = True

    normal_df = df[df["is_complex"] == False].copy()
    complex_df = df[df["is_complex"] == True].copy()
    normal_count = len(normal_df)
    complex_count = len(complex_df)
    context.log.info(f"üîÑ –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {len(df)}. "
                     f"–û–±—ã—á–Ω—ã—Ö (–±—É–¥—É—Ç –æ–±–Ω–æ–≤–ª–µ–Ω—ã/–≤—Å—Ç–∞–≤–ª–µ–Ω—ã): {normal_count}. "
                     f"–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã—Ö (–±—É–¥—É—Ç –æ–±–Ω–æ–≤–ª–µ–Ω—ã/–≤—Å—Ç–∞–≤–ª–µ–Ω—ã): {complex_count}.")
    return {"normal": {"table_name": "load_data_talons", "data": normal_df},
            "complex": {"table_name": "load_data_complex_talons", "data": complex_df}}
