# common/universal_load.py
import json
import os

import psycopg2
from dagster import OpExecutionContext

from etl_wo.common.connect_db import connect_to_db


def load_dataframe(context: OpExecutionContext, table_name: str, data, db_alias: str, mapping_file: str,
                   sql_generator) -> dict:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ DataFrame –≤ —Ç–∞–±–ª–∏—Ü—É –ë–î.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —É–∂–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ connect_to_db.

    :param context: Dagster execution context.
    :param table_name: –ò–º—è —Ç–∞–±–ª–∏—Ü—ã –≤ –ë–î.
    :param data: Pandas DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏.
    :param db_alias: –ö–ª—é—á –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'default').
    :param sql_generator: –§—É–Ω–∫—Ü–∏—è, –≥–µ–Ω–µ—Ä–∏—Ä—É—é—â–∞—è SQL-–∑–∞–ø—Ä–æ—Å—ã –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã.
    :return: –°–ª–æ–≤–∞—Ä—å —Å –∏—Ç–æ–≥–æ–≤—ã–º —á–∏—Å–ª–æ–º —Å—Ç—Ä–æ–∫, —Å—Ç–∞—Ç—É—Å–æ–º –∏ –∏–º–µ–Ω–µ–º —Ç–∞–±–ª–∏—Ü—ã.
    """
    # –£–¥–∞–ª—è–µ–º —Å—Ç–æ–ª–±—Ü—ã, –∫–æ—Ç–æ—Ä—ã–µ –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, created_at –∏ updated_at)
    data = data.drop(columns=[col for col in data.columns if col.lower() in ("created_at", "updated_at")],
                     errors='ignore')

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–∞–ø–ø–∏–Ω–≥–∞
    if not os.path.exists(mapping_file):
        context.log.error(f"Mapping file {mapping_file} not found.")
        raise FileNotFoundError(f"Mapping file {mapping_file} not found.")

    with open(mapping_file, "r", encoding="utf-8") as f:
        mappings = json.load(f)

    table_config = mappings.get("tables", {}).get(table_name, {})
    conflict_columns = table_config.get("column_check", [])
    if not conflict_columns:
        context.log.error(f"Conflict columns (column_check) not specified for table {table_name}.")
        raise ValueError(f"Conflict columns not specified for table {table_name}.")
    conflict_columns_str = ", ".join(conflict_columns)

    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è –≤—Å—Ç–∞–≤–∫–∏
    cols = list(data.columns)
    insert_columns = cols + ["created_at", "updated_at"]

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º SQL-–∑–∞–ø—Ä–æ—Å—ã —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º conflict_columns –∏–∑ –º–∞–ø–ø–∏–Ω–≥–∞
    def sql_generator(data, table_name):
        for _, row in data.iterrows():
            sql = f"""
            INSERT INTO {table_name} ({', '.join(insert_columns)})
            VALUES ({', '.join(['%s'] * len(cols))}, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
            ON CONFLICT ({conflict_columns_str})
            DO UPDATE SET {', '.join([f"{col} = EXCLUDED.{col}" for col in cols if col not in conflict_columns])};
            """
            yield sql, tuple(row[col] for col in cols)

    # –ü–æ–ª—É—á–∞–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É–∂–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è)
    engine, conn = connect_to_db(db_alias=db_alias, organization=None, context=context)
    cursor = conn.cursor()

    # –ó–∞–ø–æ–ª–Ω—è–µ–º –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
    data.fillna("-", inplace=True)

    # –í—ã–ø–æ–ª–Ω—è–µ–º SQL-–∑–∞–ø—Ä–æ—Å—ã, —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ sql_generator'–æ–º
    for sql, params in sql_generator(data, table_name):
        cursor.execute(sql, params)

    conn.commit()

    # –ü–æ–ª—É—á–∞–µ–º –∏—Ç–æ–≥–æ–≤–æ–µ —á–∏—Å–ª–æ —Å—Ç—Ä–æ–∫ –≤ —Ç–∞–±–ª–∏—Ü–µ
    cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
    final_count = cursor.fetchone()[0]

    cursor.close()
    conn.close()

    context.log.info(f"üì§ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ {table_name}. –ò—Ç–æ–≥–æ–≤–æ–µ —á–∏—Å–ª–æ —Å—Ç—Ä–æ–∫: {final_count}")
    return {"table_name": table_name, "status": "success", "final_count": final_count}
